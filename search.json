[
  {
    "objectID": "pages/040-tidyverse.html",
    "href": "pages/040-tidyverse.html",
    "title": "Tidy data",
    "section": "",
    "text": "The tidyverse is founded on the philosophy of tidy data. This philosophy says that, if you format your data in a “tidy manner”, then this simplifies all later data manipulation and visualisation. The visualisation and data analysis functions in the tidyverse are thus built on the assumption that the data they process is “tidy”.\nSo, what is “tidy data”. This is detailed very clearly in R for Data Science (2e) by Hadley Wickham, Mine Çetinkaya-Rundel and Garrett Grolemund. In summary, “tidy data” follows three interrelated rules;\n\nEach variable has its own column\nEach observation has its own row\nEach value must have its own cell\n\nLet’s look at how this applies to the Met Office data set we saw in the last section.\nEach row in this data set corresponds to observations that are collected throughout the year;\nDATE      JAN   FEB   MAR   APR   MAY   JUN   JUL   AUG   SEP   OCT   NOV   DEC     YEAR\n1659      3.0   4.0   6.0   7.0  11.0  13.0  16.0  16.0  13.0  10.0   5.0   2.0     8.87\n1660      0.0   4.0   6.0   9.0  11.0  14.0  15.0  16.0  13.0  10.0   6.0   5.0     9.10\n1661      5.0   5.0   6.0   8.0  11.0  14.0  15.0  15.0  13.0  11.0   8.0   6.0     9.78\nSo, is this data tidy? Let’s look at the rules;\n\nNo, the month name is a variable that specifies in which month the observation was taken. It should be in its own column and not used as a column header,\nNo, a row contains 12 observations across a year, plus an average of the rows\nNo, the value of the month variable, e.g. for January 1659 is a column header and does not have its own cell. And the YEAR column is not a value that matches any variable, as it refers to an average of values that is a derived from the observations of the other cells.\n\nTo tidy the data we need to perform a series of steps. These will use functions from the tidyverse dplyr and tidyr packages. These provide functions for tidying data, plus a grammar for data manipulation. Together, they will help you transform untidy data into tidy data.\n\nselect\nThe select function makes it easier to select (or deselect) one or more columns (variables) from a tibble. The general format is:\ndata %&gt;% select(column_name)           # selects a single column\ndata %&gt;% select(c(column1, column2))   # selects multiple column\ndata %&gt;% select(-column_name)          # selects all columns except a single column\ndata %&gt;% select(-c(column1, column2))  # selects except multiple columns\nIn our case, the YEAR column contains a derived value (the mean average) and should be removed as it is not a variable of an observation. We can do this using;\n\ntemperature %&gt;% select(-YEAR)\n\n# A tibble: 362 × 13\n    DATE   JAN   FEB   MAR   APR   MAY   JUN   JUL   AUG   SEP   OCT   NOV   DEC\n   &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  1659     3     4     6     7    11    13    16    16    13    10     5     2\n 2  1660     0     4     6     9    11    14    15    16    13    10     6     5\n 3  1661     5     5     6     8    11    14    15    15    13    11     8     6\n 4  1662     5     6     6     8    11    15    15    15    13    11     6     3\n 5  1663     1     1     5     7    10    14    15    15    13    10     7     5\n 6  1664     4     5     5     8    11    15    16    16    13     9     6     4\n 7  1665     1     1     5     7    10    14    16    15    13     9     6     2\n 8  1666     4     5     6     8    11    15    18    17    14    11     6     3\n 9  1667     0     4     2     7    10    15    17    16    13     9     6     3\n10  1668     5     5     5     8    10    14    16    16    14    10     6     5\n# ℹ 352 more rows\n\n\n\n\nPivoting with pivot_longer\nNext, we need to pivot (rotate) the table so that the observation for each month is on its own row in the table. We do this using the pivot_longer function. You need to pass to this function the names of the columns that contain observations. These columns will become rows, with the value going into a new column named according to values_to, and the old column name moving into a new column named according to names_to, e.g.\npivot_longer(c(\"JAN\", \"FEB\", \"MAR\"), \n             names_to=\"month\",\n             values_to=\"temperature\")\nwould move the values of the “JAN”, “FEB” and “MAR” columns into a new column called “temperature”, and the actual month names will be moved into a new column called “month”.\nFor our data set, we would use;\n\ntemperature %&gt;% \n    select(-YEAR) %&gt;%\n    pivot_longer(c(\"JAN\", \"FEB\", \"MAR\", \"APR\", \"MAY\", \"JUN\",\n                   \"JUL\", \"AUG\", \"SEP\", \"OCT\", \"NOV\", \"DEC\"),\n                 names_to=\"month\",\n                 values_to=\"temperature\")\n\n# A tibble: 4,344 × 3\n    DATE month temperature\n   &lt;int&gt; &lt;chr&gt;       &lt;dbl&gt;\n 1  1659 JAN             3\n 2  1659 FEB             4\n 3  1659 MAR             6\n 4  1659 APR             7\n 5  1659 MAY            11\n 6  1659 JUN            13\n 7  1659 JUL            16\n 8  1659 AUG            16\n 9  1659 SEP            13\n10  1659 OCT            10\n# ℹ 4,334 more rows\n\n\n\n\nRenaming columns\nOur data is now “tidy”. Each variable (DATE, month, temperature) has its own column, each observation has its own row, and each value has its own cell.\nHowever, “DATE” is a poor choice of name for the “year” variable. We can rename a column using the rename function. The general format is;\nrename(new_name=old_name)\nand so, for our data we could use;\n\ntemperature %&gt;%\n    select(-YEAR) %&gt;%\n    pivot_longer(c(\"JAN\", \"FEB\", \"MAR\", \"APR\", \"MAY\", \"JUN\",\n                   \"JUL\", \"AUG\", \"SEP\", \"OCT\", \"NOV\", \"DEC\"),\n                 names_to=\"month\",\n                 values_to=\"temperature\") %&gt;%\n    rename(year=DATE)\n\n# A tibble: 4,344 × 3\n    year month temperature\n   &lt;int&gt; &lt;chr&gt;       &lt;dbl&gt;\n 1  1659 JAN             3\n 2  1659 FEB             4\n 3  1659 MAR             6\n 4  1659 APR             7\n 5  1659 MAY            11\n 6  1659 JUN            13\n 7  1659 JUL            16\n 8  1659 AUG            16\n 9  1659 SEP            13\n10  1659 OCT            10\n# ℹ 4,334 more rows\n\n\n\n\nFactors and mutate\nThe final problem to solve is that the value of the variable “month” for each observation is just a character string. As it is, R does not know that this is a categorical variable that can only take one of a number of valid values (e.g. in this case, only months of the year).\nIf there were any typos (e.g. “JULY” instead of “JUL”) then we would not see that error. Also, if we sorted by month then they would sort alphabetically (APR before JAN), instead of in the correct month order.\nTo solve this, we need to convert the month into a factor. A factor is used to represent categorical data. A factor must have a value that corresponds to one of its levels. For example, lets now create the levels for a factor to represent months of the year;\n\nmonth_levels &lt;- c(\"JAN\", \"FEB\", \"MAR\", \"APR\", \"MAY\", \"JUN\",\n                  \"JUL\", \"AUG\", \"SEP\", \"OCT\", \"NOV\", \"DEC\")\n\nThis list of strings sets the valid values of the factor, and the order in which they should be arranged.\nTo factor data, we use the factor function which is included in base R. The general syntax is;\nfactor(data, levels)\nThis would return the passed data factored into one of the levels specified in levels.\nIn our case, we will need to perform\nfactor(data, month_levels)\none each of the values of the month variable for each observation.\nTo do this, we need to edit our data to translate each month string into a month factor. Editing of a tibble is performed by the mutate function, e.g.\nmutate(temperature=temperature+5)\nwould edit the “temperature” column variable, and add “5” to every single value in this column. In our case, we want to factor each value of the month column variable, so we need\nmutate(month=factor(month, month_levels))\nPutting this together with what we have before, and assigning the tibble to a new variable called historical_temperature, we now get;\n\nhistorical_temperature &lt;- temperature %&gt;%\n    select(-YEAR) %&gt;%\n    pivot_longer(c(\"JAN\", \"FEB\", \"MAR\", \"APR\", \"MAY\", \"JUN\",\n                   \"JUL\", \"AUG\", \"SEP\", \"OCT\", \"NOV\", \"DEC\"),\n                 names_to=\"month\",\n                 values_to=\"temperature\") %&gt;%\n    rename(year=DATE) %&gt;%\n    mutate(month=factor(month, month_levels))\n\nhistorical_temperature\n\n# A tibble: 4,344 × 3\n    year month temperature\n   &lt;int&gt; &lt;fct&gt;       &lt;dbl&gt;\n 1  1659 JAN             3\n 2  1659 FEB             4\n 3  1659 MAR             6\n 4  1659 APR             7\n 5  1659 MAY            11\n 6  1659 JUN            13\n 7  1659 JUL            16\n 8  1659 AUG            16\n 9  1659 SEP            13\n10  1659 OCT            10\n# ℹ 4,334 more rows\n\n\nAs you can see, the data type for “month” is now “fct”, which is short for “factor”.",
    "crumbs": [
      "Tidy data"
    ]
  },
  {
    "objectID": "pages/060-ggplot.html",
    "href": "pages/060-ggplot.html",
    "title": "Plotting",
    "section": "",
    "text": "Plotting of data in modern R is handled by ggplot2, which is installed as part of the tidyverse. There is an excellent cheat sheet and a great free online book, ggplot2: Elegant graphics for data analysis, by Hadley Wickham, Danielle Navarro, and Thomas Lin Pedersen.\nWe cannot cover all of ggplot2 in this workshop, so you are strongly encouraged to read the book and cheat sheet. For today, we will give a quick overview of how to create some simple graphs.\nFirst we load the tidyverse in the same way as previously;\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nNext we will load some data to plot. We will use the climate data from the previous section (available from cetml1659on.txt).\nPlotting works best with tidy data, so we will load and tidy the data as in the previous section;\n\ntemperature &lt;- read_table(\n    \"https://raw.githubusercontent.com/Bristol-Training/intro-data-analysis-r/refs/heads/main/data/cetml1659on.txt\",\n    skip=6,\n    na=c(\"-99.99\", \"-99.9\"),\n    col_types=cols(\"DATE\"=col_integer())\n)\n\nmonth_levels &lt;- c(\"JAN\", \"FEB\", \"MAR\", \"APR\", \"MAY\", \"JUN\",\n                  \"JUL\", \"AUG\", \"SEP\", \"OCT\", \"NOV\", \"DEC\")\n\nhistorical_temperature &lt;- temperature %&gt;%\n    select(-YEAR) %&gt;%\n    pivot_longer(c(\"JAN\", \"FEB\", \"MAR\", \"APR\", \"MAY\", \"JUN\",\n                   \"JUL\", \"AUG\", \"SEP\", \"OCT\", \"NOV\", \"DEC\"),\n                 names_to=\"month\",\n                 values_to=\"temperature\") %&gt;%\n    rename(year=DATE) %&gt;%\n    mutate(month=factor(month, month_levels))\n\nNext, we will use ggplot to draw a graph (we will explain how this works after drawing). You should see a graph similar to this:\n\nggplot(historical_temperature, aes(x = year, y = temperature)) + geom_point()\n\nWarning: Removed 5 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nThis command has drawn a scatter plot of the data contained in the tibble historical_temperature, putting the year column on the x-axis, and the temperature column on the y-axis.\nggplot is written to follow a specific “grammar of visualisation”. There are three key components;\n\ndata,\nA set of aesthetic mappings between variables in the data and visual properties of the graph, and\none or more layers that describe how to render each observation.\n\nThese are entered via the general form\nggplot( data, aesthetic ) + layer1 + layer2 + layer3...\nThe data is a tibble containing tidy data with one observation per row, and one variable per column.\nThe aesthetic is a mapping specified via the aes function, which maps the variables to axes, colours or other graphical properties.\nThe layers (layer1, layer2 etc) are specific renderings of the data, e.g. geom_point() will draw points (scatter plot), geom_line() will draw lines (line graph) etc.\n\n\nYou can combine analysis with plotting, e.g. here we plot the average yearly temperature as a line graph.\n\nggplot(historical_temperature %&gt;%\n           group_by(year) %&gt;%\n           summarise(temperature=mean(temperature)), \n       aes(x = year, y = temperature)) +\n    geom_line() + \n    geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\nWarning: Removed 1 row containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n\n\nHere we’ve added two layers; geom_line() to draw a line graph, and geom_smooth() to add a fitted line with errors.\nWe could do more. For example, here we add a new variable (column) to the data that is the decade in which the observation was taken;\n\nhistorical_temperature[\"decade\"] &lt;- (historical_temperature[\"year\"] %/% 10) * 10\n\n(%/% means “integer division”, so 1655 %/% 10 equals 165, which becomes 1650 when multiplied by 10)\nThis enables us to draw a line graph of the average temperature each decade;\n\nggplot(historical_temperature %&gt;%\n           group_by(decade) %&gt;%\n           summarise(temperature=mean(temperature)), \n       aes(x = decade, y = temperature)) + \n       geom_line()\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n\n\nA line chart is not a good choice for this plot, as it doesn’t show the underlying statistics of the average. Instead, a box-and-whisker or violin plot would be better. To use this, we need to specify the grouping in the aesthetic, e.g.\n\nggplot(historical_temperature, \n       aes(x = decade, y = temperature, group=decade)) + \n       geom_violin()\n\nWarning: Removed 5 rows containing non-finite outside the scale range\n(`stat_ydensity()`).\n\n\n\n\n\n\n\n\n\nFinally, the global aesthetic set in ggplot can be overridden by setting it in the layers themselves. For example, here we overlay a smooth line over the violin plot;\n\nggplot(historical_temperature, \n       aes(x=year, y = temperature)) + \n       geom_violin(aes(group=decade)) + \n       geom_smooth()\n\nWarning: Removed 5 rows containing non-finite outside the scale range\n(`stat_ydensity()`).\n\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\nWarning: Removed 5 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\n\n\n\n\n\n\n\nNote how the group aesthetic has to be set only for the violin plot.\nYou can save your plots to a file using the ggsave function. This will save the last plot drawn to a file, with filename, size, format etc. all controlled via arguments to this function, e.g.\nggsave(\"violin.pdf\", device=\"pdf\", dpi=\"print\")\nwould save the plot to a file called violin.pdf, in PDF format, using a resolution (dpi) that is suitable for printing.\n\n\n\n\n\n\nExercise\n\n\n\nCreate a graph that shows the average maximum temperature by month. Draw this as a line graph. Note that you may need to add group=\"decade\" to the aesthetic so that the line layer can join together the points.\nCreate a graph that shows the change in average temperature in December per decade. Draw this as a scatter plot, with a smooth trend line added.\nCreate a graph that shows the change in average temperature by century. Draw this as a line graph with a smooth trend line added. Note that you may need to adjust the span value if the number of data points is too few to draw a very smooth line.\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nFirst load the tidyverse, then read in all of the data and tidy it up…\n\nlibrary(tidyverse)\n\ntemperature &lt;- read_table(\n    \"https://raw.githubusercontent.com/Bristol-Training/intro-data-analysis-r/refs/heads/main/data/cetml1659on.txt\",\n    skip=6,\n    na=c(\"-99.99\", \"-99.9\"),\n    col_types=cols(\"DATE\"=col_integer())\n)\n\nmonth_levels &lt;- c(\"JAN\", \"FEB\", \"MAR\", \"APR\", \"MAY\", \"JUN\",\n                  \"JUL\", \"AUG\", \"SEP\", \"OCT\", \"NOV\", \"DEC\")\n\nhistorical_temperature &lt;- temperature %&gt;%\n    select(-YEAR) %&gt;%\n    pivot_longer(c(\"JAN\", \"FEB\", \"MAR\", \"APR\", \"MAY\", \"JUN\",\n                   \"JUL\", \"AUG\", \"SEP\", \"OCT\", \"NOV\", \"DEC\"),\n                 names_to=\"month\",\n                 values_to=\"temperature\") %&gt;%\n    rename(year=DATE) %&gt;%\n    mutate(month=factor(month, month_levels))\n\nNext, add in the “decade” and “century” variables (columns) as we will be using them later…\n\nhistorical_temperature[\"decade\"] &lt;- (historical_temperature[\"year\"] %/% 10) * 10\nhistorical_temperature[\"century\"] &lt;- (historical_temperature[\"year\"] %/% 100) * 100\nhistorical_temperature\n\n# A tibble: 4,344 × 5\n    year month temperature decade century\n   &lt;int&gt; &lt;fct&gt;       &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n 1  1659 JAN             3   1650    1600\n 2  1659 FEB             4   1650    1600\n 3  1659 MAR             6   1650    1600\n 4  1659 APR             7   1650    1600\n 5  1659 MAY            11   1650    1600\n 6  1659 JUN            13   1650    1600\n 7  1659 JUL            16   1650    1600\n 8  1659 AUG            16   1650    1600\n 9  1659 SEP            13   1650    1600\n10  1659 OCT            10   1650    1600\n# ℹ 4,334 more rows\n\n\nGraph that shows the average maximum temperature per month…\n\nggplot(historical_temperature %&gt;%\n         group_by(month) %&gt;%\n         summarise(max_temp=max(temperature, na.rm=TRUE), .groups=\"drop\"),\n       aes(x=month, y=max_temp, group=\"month\")) + \n  geom_line()\n\n\n\n\n\n\n\n\nChange in average temperature in December per decade.\n\nggplot( historical_temperature %&gt;%\n          filter(month==\"DEC\") %&gt;%\n          group_by(decade) %&gt;%\n          summarise(average=mean(temperature, na.rm=TRUE), .groups=\"drop\"),\n        aes(x=decade, y=average)\n      ) + \n  geom_point() +\n  geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\nWarning: Removed 1 row containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nChange in average temperature per century, plus a smooth trend line\n\nggplot( historical_temperature %&gt;%\n          group_by(century) %&gt;%\n          summarise(average=mean(temperature, na.rm=TRUE), .groups=\"drop\"),\n        aes(x=century, y=average)) + \n  geom_point() + \n  geom_smooth(span=2.0)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'",
    "crumbs": [
      "Plotting"
    ]
  },
  {
    "objectID": "pages/060-ggplot.html#plotting-data",
    "href": "pages/060-ggplot.html#plotting-data",
    "title": "Plotting",
    "section": "",
    "text": "Plotting of data in modern R is handled by ggplot2, which is installed as part of the tidyverse. There is an excellent cheat sheet and a great free online book, ggplot2: Elegant graphics for data analysis, by Hadley Wickham, Danielle Navarro, and Thomas Lin Pedersen.\nWe cannot cover all of ggplot2 in this workshop, so you are strongly encouraged to read the book and cheat sheet. For today, we will give a quick overview of how to create some simple graphs.\nFirst we load the tidyverse in the same way as previously;\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nNext we will load some data to plot. We will use the climate data from the previous section (available from cetml1659on.txt).\nPlotting works best with tidy data, so we will load and tidy the data as in the previous section;\n\ntemperature &lt;- read_table(\n    \"https://raw.githubusercontent.com/Bristol-Training/intro-data-analysis-r/refs/heads/main/data/cetml1659on.txt\",\n    skip=6,\n    na=c(\"-99.99\", \"-99.9\"),\n    col_types=cols(\"DATE\"=col_integer())\n)\n\nmonth_levels &lt;- c(\"JAN\", \"FEB\", \"MAR\", \"APR\", \"MAY\", \"JUN\",\n                  \"JUL\", \"AUG\", \"SEP\", \"OCT\", \"NOV\", \"DEC\")\n\nhistorical_temperature &lt;- temperature %&gt;%\n    select(-YEAR) %&gt;%\n    pivot_longer(c(\"JAN\", \"FEB\", \"MAR\", \"APR\", \"MAY\", \"JUN\",\n                   \"JUL\", \"AUG\", \"SEP\", \"OCT\", \"NOV\", \"DEC\"),\n                 names_to=\"month\",\n                 values_to=\"temperature\") %&gt;%\n    rename(year=DATE) %&gt;%\n    mutate(month=factor(month, month_levels))\n\nNext, we will use ggplot to draw a graph (we will explain how this works after drawing). You should see a graph similar to this:\n\nggplot(historical_temperature, aes(x = year, y = temperature)) + geom_point()\n\nWarning: Removed 5 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nThis command has drawn a scatter plot of the data contained in the tibble historical_temperature, putting the year column on the x-axis, and the temperature column on the y-axis.\nggplot is written to follow a specific “grammar of visualisation”. There are three key components;\n\ndata,\nA set of aesthetic mappings between variables in the data and visual properties of the graph, and\none or more layers that describe how to render each observation.\n\nThese are entered via the general form\nggplot( data, aesthetic ) + layer1 + layer2 + layer3...\nThe data is a tibble containing tidy data with one observation per row, and one variable per column.\nThe aesthetic is a mapping specified via the aes function, which maps the variables to axes, colours or other graphical properties.\nThe layers (layer1, layer2 etc) are specific renderings of the data, e.g. geom_point() will draw points (scatter plot), geom_line() will draw lines (line graph) etc.\n\n\nYou can combine analysis with plotting, e.g. here we plot the average yearly temperature as a line graph.\n\nggplot(historical_temperature %&gt;%\n           group_by(year) %&gt;%\n           summarise(temperature=mean(temperature)), \n       aes(x = year, y = temperature)) +\n    geom_line() + \n    geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\nWarning: Removed 1 row containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n\n\nHere we’ve added two layers; geom_line() to draw a line graph, and geom_smooth() to add a fitted line with errors.\nWe could do more. For example, here we add a new variable (column) to the data that is the decade in which the observation was taken;\n\nhistorical_temperature[\"decade\"] &lt;- (historical_temperature[\"year\"] %/% 10) * 10\n\n(%/% means “integer division”, so 1655 %/% 10 equals 165, which becomes 1650 when multiplied by 10)\nThis enables us to draw a line graph of the average temperature each decade;\n\nggplot(historical_temperature %&gt;%\n           group_by(decade) %&gt;%\n           summarise(temperature=mean(temperature)), \n       aes(x = decade, y = temperature)) + \n       geom_line()\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n\n\nA line chart is not a good choice for this plot, as it doesn’t show the underlying statistics of the average. Instead, a box-and-whisker or violin plot would be better. To use this, we need to specify the grouping in the aesthetic, e.g.\n\nggplot(historical_temperature, \n       aes(x = decade, y = temperature, group=decade)) + \n       geom_violin()\n\nWarning: Removed 5 rows containing non-finite outside the scale range\n(`stat_ydensity()`).\n\n\n\n\n\n\n\n\n\nFinally, the global aesthetic set in ggplot can be overridden by setting it in the layers themselves. For example, here we overlay a smooth line over the violin plot;\n\nggplot(historical_temperature, \n       aes(x=year, y = temperature)) + \n       geom_violin(aes(group=decade)) + \n       geom_smooth()\n\nWarning: Removed 5 rows containing non-finite outside the scale range\n(`stat_ydensity()`).\n\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\nWarning: Removed 5 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\n\n\n\n\n\n\n\nNote how the group aesthetic has to be set only for the violin plot.\nYou can save your plots to a file using the ggsave function. This will save the last plot drawn to a file, with filename, size, format etc. all controlled via arguments to this function, e.g.\nggsave(\"violin.pdf\", device=\"pdf\", dpi=\"print\")\nwould save the plot to a file called violin.pdf, in PDF format, using a resolution (dpi) that is suitable for printing.\n\n\n\n\n\n\nExercise\n\n\n\nCreate a graph that shows the average maximum temperature by month. Draw this as a line graph. Note that you may need to add group=\"decade\" to the aesthetic so that the line layer can join together the points.\nCreate a graph that shows the change in average temperature in December per decade. Draw this as a scatter plot, with a smooth trend line added.\nCreate a graph that shows the change in average temperature by century. Draw this as a line graph with a smooth trend line added. Note that you may need to adjust the span value if the number of data points is too few to draw a very smooth line.\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nFirst load the tidyverse, then read in all of the data and tidy it up…\n\nlibrary(tidyverse)\n\ntemperature &lt;- read_table(\n    \"https://raw.githubusercontent.com/Bristol-Training/intro-data-analysis-r/refs/heads/main/data/cetml1659on.txt\",\n    skip=6,\n    na=c(\"-99.99\", \"-99.9\"),\n    col_types=cols(\"DATE\"=col_integer())\n)\n\nmonth_levels &lt;- c(\"JAN\", \"FEB\", \"MAR\", \"APR\", \"MAY\", \"JUN\",\n                  \"JUL\", \"AUG\", \"SEP\", \"OCT\", \"NOV\", \"DEC\")\n\nhistorical_temperature &lt;- temperature %&gt;%\n    select(-YEAR) %&gt;%\n    pivot_longer(c(\"JAN\", \"FEB\", \"MAR\", \"APR\", \"MAY\", \"JUN\",\n                   \"JUL\", \"AUG\", \"SEP\", \"OCT\", \"NOV\", \"DEC\"),\n                 names_to=\"month\",\n                 values_to=\"temperature\") %&gt;%\n    rename(year=DATE) %&gt;%\n    mutate(month=factor(month, month_levels))\n\nNext, add in the “decade” and “century” variables (columns) as we will be using them later…\n\nhistorical_temperature[\"decade\"] &lt;- (historical_temperature[\"year\"] %/% 10) * 10\nhistorical_temperature[\"century\"] &lt;- (historical_temperature[\"year\"] %/% 100) * 100\nhistorical_temperature\n\n# A tibble: 4,344 × 5\n    year month temperature decade century\n   &lt;int&gt; &lt;fct&gt;       &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n 1  1659 JAN             3   1650    1600\n 2  1659 FEB             4   1650    1600\n 3  1659 MAR             6   1650    1600\n 4  1659 APR             7   1650    1600\n 5  1659 MAY            11   1650    1600\n 6  1659 JUN            13   1650    1600\n 7  1659 JUL            16   1650    1600\n 8  1659 AUG            16   1650    1600\n 9  1659 SEP            13   1650    1600\n10  1659 OCT            10   1650    1600\n# ℹ 4,334 more rows\n\n\nGraph that shows the average maximum temperature per month…\n\nggplot(historical_temperature %&gt;%\n         group_by(month) %&gt;%\n         summarise(max_temp=max(temperature, na.rm=TRUE), .groups=\"drop\"),\n       aes(x=month, y=max_temp, group=\"month\")) + \n  geom_line()\n\n\n\n\n\n\n\n\nChange in average temperature in December per decade.\n\nggplot( historical_temperature %&gt;%\n          filter(month==\"DEC\") %&gt;%\n          group_by(decade) %&gt;%\n          summarise(average=mean(temperature, na.rm=TRUE), .groups=\"drop\"),\n        aes(x=decade, y=average)\n      ) + \n  geom_point() +\n  geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\nWarning: Removed 1 row containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nChange in average temperature per century, plus a smooth trend line\n\nggplot( historical_temperature %&gt;%\n          group_by(century) %&gt;%\n          summarise(average=mean(temperature, na.rm=TRUE), .groups=\"drop\"),\n        aes(x=century, y=average)) + \n  geom_point() + \n  geom_smooth(span=2.0)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'",
    "crumbs": [
      "Plotting"
    ]
  },
  {
    "objectID": "pages/050-analysis.html",
    "href": "pages/050-analysis.html",
    "title": "Data analysis",
    "section": "",
    "text": "Up to this point, we have just been learning how to read data and make it tidy. This was a lot of work. The pay-off is that now the analysis of the data will be much easier and straightforward.\nThis is intentional. Data cleaning is the messiest and most ambiguous part of data science. A truism is that data cleaning takes 80% of the time of any data science project. However, without this effort, data analysis and visualisation would be similarly messy and time consuming. By cleaning first, we can perform data analysis and visualisation using clean, consistent, well-tested and tidy tools.\n\n\nYou can perform summary analysis on data in a tibble using the summarise function from the dply package.\nsummarise will create a new tibble that is a summary of the input tibble, based on grouping and a summarising function. Summarising functions include;\n\nCenter: mean(), median()\nSpread: sd(), IQR(), mad()\nRange: min(), max(), quantile()\nPosition: first(), last(), nth()\nCount: n(), n_distinct()\nLogical: any(), all()\n\nFor example, we can calculate the mean average temperature using:\n\nhistorical_temperature %&gt;% \n    summarise(\"average temperature\"=mean(temperature, na.rm=TRUE))\n\n# A tibble: 1 × 1\n  `average temperature`\n                  &lt;dbl&gt;\n1                  9.25\n\n\nNote that we used na.rm=TRUE to tell the function to ignore NA values.\nThis has created a new tibble, where the column called “average temperature” contains the mean average temperature.\n\n\n\nEach row of tidy data corresponds to a single observation. We can group observations together into groups using group_by. We can then feed these groups into summaries.\nFor example, we can group by year and summarise by the mean function to calculate the average temperature for each year;\n\nhistorical_temperature %&gt;% \n    group_by(year) %&gt;%\n    summarise(\"average temperature\"=mean(temperature, na.rm=TRUE))\n\n# A tibble: 362 × 2\n    year `average temperature`\n   &lt;int&gt;                 &lt;dbl&gt;\n 1  1659                  8.83\n 2  1660                  9.08\n 3  1661                  9.75\n 4  1662                  9.5 \n 5  1663                  8.58\n 6  1664                  9.33\n 7  1665                  8.25\n 8  1666                  9.83\n 9  1667                  8.5 \n10  1668                  9.5 \n# ℹ 352 more rows\n\n\nor, we could calculate the average temperature for each month via;\n\nhistorical_temperature %&gt;%\n    group_by(month) %&gt;%\n    summarise(\"average temperature\"=mean(temperature, na.rm=TRUE))\n\n# A tibble: 12 × 2\n   month `average temperature`\n   &lt;fct&gt;                 &lt;dbl&gt;\n 1 JAN                    3.28\n 2 FEB                    3.89\n 3 MAR                    5.35\n 4 APR                    7.95\n 5 MAY                   11.2 \n 6 JUN                   14.3 \n 7 JUL                   16.0 \n 8 AUG                   15.6 \n 9 SEP                   13.3 \n10 OCT                    9.73\n11 NOV                    6.08\n12 DEC                    4.12\n\n\n\n\n\nWe can then use the filter, also from dplyr, to filter observations (rows) before we group. For example, we could filter the years in the 18th Century (year&lt;1800 & year&gt;=1700) and calculate the average monthly temperatures then via;\n\nhistorical_temperature %&gt;%\n    filter(year&lt;1800 & year&gt;=1700) %&gt;%\n    group_by(month) %&gt;%\n    summarise(\"18th Century\"=mean(temperature, na.rm=TRUE))\n\n# A tibble: 12 × 2\n   month `18th Century`\n   &lt;fct&gt;          &lt;dbl&gt;\n 1 JAN             2.89\n 2 FEB             3.80\n 3 MAR             5.04\n 4 APR             7.88\n 5 MAY            11.3 \n 6 JUN            14.5 \n 7 JUL            16.0 \n 8 AUG            15.8 \n 9 SEP            13.5 \n10 OCT             9.40\n11 NOV             5.84\n12 DEC             3.89\n\n\nWe could then repeat this for the 21st Century…\n\nhistorical_temperature %&gt;%\n    filter(year&gt;=2000) %&gt;%\n    group_by(month) %&gt;%\n    summarise(\"21st Century\"=mean(temperature, na.rm=TRUE))\n\n# A tibble: 12 × 2\n   month `21st Century`\n   &lt;fct&gt;          &lt;dbl&gt;\n 1 JAN             4.73\n 2 FEB             4.93\n 3 MAR             6.60\n 4 APR             9.08\n 5 MAY            12.0 \n 6 JUN            14.9 \n 7 JUL            16.8 \n 8 AUG            16.4 \n 9 SEP            14.3 \n10 OCT            11.2 \n11 NOV             7.44\n12 DEC             5.12\n\n\n\n\n\n\n\n\nExercise\n\n\n\nUse filter, group_by and summarise to create tibbles that contain the average monthly temperatures for the 17th and 21st Centuries. Take the difference of these to calculate the change in average temperature for each month.\nNext calculate the minimum and maximum monthly temperatures for the 17th and 21st Centuries. Again, calculate the change in minimum and maximum temperatures for each month.\nFinally, what is the average increase in maximum monthly temperatures between the 16th and 21st Centuries?\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nlibrary(tidyverse)\n\nLoad the data…\n\ntemperature &lt;- read_table(\n    \"https://raw.githubusercontent.com/Bristol-Training/intro-data-analysis-r/refs/heads/main/data/cetml1659on.txt\",\n    skip=6,\n    na=c(\"-99.99\", \"-99.9\"),\n    col_types=cols(\"DATE\"=col_integer())\n)\n\nCreate the month levels\n\nmonth_levels &lt;- c(\"JAN\", \"FEB\", \"MAR\", \"APR\", \"MAY\", \"JUN\",\n                  \"JUL\", \"AUG\", \"SEP\", \"OCT\", \"NOV\", \"DEC\")\n\nTidy the data…\n\nhistorical_temperature &lt;- temperature %&gt;%\n    select(-YEAR) %&gt;%\n    pivot_longer(c(\"JAN\", \"FEB\", \"MAR\", \"APR\", \"MAY\", \"JUN\",\n                   \"JUL\", \"AUG\", \"SEP\", \"OCT\", \"NOV\", \"DEC\"),\n                 names_to=\"month\",\n                 values_to=\"temperature\") %&gt;%\n    rename(year=DATE) %&gt;%\n    mutate(month=factor(month, month_levels))\n\nCalculate the mean monthly temperatures in the 17th Century\n\nc17th &lt;- historical_temperature %&gt;%\n     filter(year&lt;1700 & year&gt;=1600) %&gt;%\n     group_by(month) %&gt;%\n     summarise(\"temperature\"=mean(temperature, na.rm=TRUE), .groups=\"drop\")\n\n(the .groups=\"drop\" removes a warning message in newer versions of R. It is experimental, e.g. see this stackoverflow post)\nCalculate the mean monthly temperatures in the 21st Century\n\nc21st &lt;- historical_temperature %&gt;%\n     filter(year&gt;=2000) %&gt;%\n     group_by(month) %&gt;%\n     summarise(\"temperature\"=mean(temperature, na.rm=TRUE), .groups=\"drop\")\n\nNow add the difference to the c21st table and print it out\n\nc21st[\"change\"] &lt;- c21st[\"temperature\"] - c17th[\"temperature\"]\nc21st\n\n# A tibble: 12 × 3\n   month temperature change\n   &lt;fct&gt;       &lt;dbl&gt;  &lt;dbl&gt;\n 1 JAN          4.73  2.16 \n 2 FEB          4.93  2.00 \n 3 MAR          6.60  1.96 \n 4 APR          9.08  1.80 \n 5 MAY         12.0   1.33 \n 6 JUN         14.9   0.818\n 7 JUL         16.8   1.12 \n 8 AUG         16.4   1.26 \n 9 SEP         14.3   1.71 \n10 OCT         11.2   1.91 \n11 NOV          7.44  1.91 \n12 DEC          5.12  1.76 \n\n\nFrom this we can see that most of the warming is focused on the winter months.\nWe will now repeat this for the maximum and minimum temperatures…\n\nc17th_max &lt;- historical_temperature %&gt;%\n     filter(year&lt;1700 & year&gt;=1600) %&gt;%\n     group_by(month) %&gt;%\n     summarise(\"temperature\"=max(temperature, na.rm=TRUE), .groups=\"drop\")\nc21st_max &lt;- historical_temperature %&gt;%\n     filter(year&gt;=2000) %&gt;%\n     group_by(month) %&gt;%\n     summarise(\"temperature\"=max(temperature, na.rm=TRUE), .groups=\"drop\")\nc21st_max[\"change\"] &lt;- c21st_max[\"temperature\"] - c17th_max[\"temperature\"]\n\nc21st_max\n\n# A tibble: 12 × 3\n   month temperature change\n   &lt;fct&gt;       &lt;dbl&gt;  &lt;dbl&gt;\n 1 JAN           7    0.5  \n 2 FEB           7    1    \n 3 MAR           8.7  1.7  \n 4 APR          11.8  2.3  \n 5 MAY          13.4  0.400\n 6 JUN          16.1 -1.90 \n 7 JUL          19.7  1.7  \n 8 AUG          18.3  1.3  \n 9 SEP          16.8  1.8  \n10 OCT          13.3  1.8  \n11 NOV           9.6  1.6  \n12 DEC           9.7  3.2  \n\n\n\nc17th_min &lt;- historical_temperature %&gt;%\n     filter(year&lt;1700 & year&gt;=1600) %&gt;%\n     group_by(month) %&gt;%\n     summarise(\"temperature\"=min(temperature, na.rm=TRUE), .groups=\"drop\")\nc21st_min &lt;- historical_temperature %&gt;%\n     filter(year&gt;=2000) %&gt;%\n     group_by(month) %&gt;%\n     summarise(\"temperature\"=min(temperature, na.rm=TRUE), .groups=\"drop\")\nc21st_min[\"change\"] &lt;- c21st_min[\"temperature\"] - c17th_min[\"temperature\"]\n\nc21st_min\n\n# A tibble: 12 × 3\n   month temperature change\n   &lt;fct&gt;       &lt;dbl&gt;  &lt;dbl&gt;\n 1 JAN           1.4    4.4\n 2 FEB           2.8    3.8\n 3 MAR           2.7    1.7\n 4 APR           7.2    1.7\n 5 MAY          10.4    1.9\n 6 JUN          13.5    2  \n 7 JUL          15.2    1.7\n 8 AUG          14.9    1.9\n 9 SEP          12.6    2.1\n10 OCT           9.2    2.7\n11 NOV           5.2    2.2\n12 DEC          -0.7   -0.2\n\n\nFinally, we can get the average increase in monthly temperatures by calculating the mean of the change column in c21st\n\nmean(c21st[[\"change\"]])\n\n[1] 1.643698\n\n\n\n\n\nBecause we were working with tidy data the filtering and grouping of observations, and then generation of summary statistics was straightforward. This grammar (data is filtered, then grouped, then summarised) worked because the data was tidy. As we will see in the next section, a similar grammar for visualisation makes graph drawing equally logical.",
    "crumbs": [
      "Data analysis"
    ]
  },
  {
    "objectID": "pages/050-analysis.html#data-analysis",
    "href": "pages/050-analysis.html#data-analysis",
    "title": "Data analysis",
    "section": "",
    "text": "Up to this point, we have just been learning how to read data and make it tidy. This was a lot of work. The pay-off is that now the analysis of the data will be much easier and straightforward.\nThis is intentional. Data cleaning is the messiest and most ambiguous part of data science. A truism is that data cleaning takes 80% of the time of any data science project. However, without this effort, data analysis and visualisation would be similarly messy and time consuming. By cleaning first, we can perform data analysis and visualisation using clean, consistent, well-tested and tidy tools.\n\n\nYou can perform summary analysis on data in a tibble using the summarise function from the dply package.\nsummarise will create a new tibble that is a summary of the input tibble, based on grouping and a summarising function. Summarising functions include;\n\nCenter: mean(), median()\nSpread: sd(), IQR(), mad()\nRange: min(), max(), quantile()\nPosition: first(), last(), nth()\nCount: n(), n_distinct()\nLogical: any(), all()\n\nFor example, we can calculate the mean average temperature using:\n\nhistorical_temperature %&gt;% \n    summarise(\"average temperature\"=mean(temperature, na.rm=TRUE))\n\n# A tibble: 1 × 1\n  `average temperature`\n                  &lt;dbl&gt;\n1                  9.25\n\n\nNote that we used na.rm=TRUE to tell the function to ignore NA values.\nThis has created a new tibble, where the column called “average temperature” contains the mean average temperature.\n\n\n\nEach row of tidy data corresponds to a single observation. We can group observations together into groups using group_by. We can then feed these groups into summaries.\nFor example, we can group by year and summarise by the mean function to calculate the average temperature for each year;\n\nhistorical_temperature %&gt;% \n    group_by(year) %&gt;%\n    summarise(\"average temperature\"=mean(temperature, na.rm=TRUE))\n\n# A tibble: 362 × 2\n    year `average temperature`\n   &lt;int&gt;                 &lt;dbl&gt;\n 1  1659                  8.83\n 2  1660                  9.08\n 3  1661                  9.75\n 4  1662                  9.5 \n 5  1663                  8.58\n 6  1664                  9.33\n 7  1665                  8.25\n 8  1666                  9.83\n 9  1667                  8.5 \n10  1668                  9.5 \n# ℹ 352 more rows\n\n\nor, we could calculate the average temperature for each month via;\n\nhistorical_temperature %&gt;%\n    group_by(month) %&gt;%\n    summarise(\"average temperature\"=mean(temperature, na.rm=TRUE))\n\n# A tibble: 12 × 2\n   month `average temperature`\n   &lt;fct&gt;                 &lt;dbl&gt;\n 1 JAN                    3.28\n 2 FEB                    3.89\n 3 MAR                    5.35\n 4 APR                    7.95\n 5 MAY                   11.2 \n 6 JUN                   14.3 \n 7 JUL                   16.0 \n 8 AUG                   15.6 \n 9 SEP                   13.3 \n10 OCT                    9.73\n11 NOV                    6.08\n12 DEC                    4.12\n\n\n\n\n\nWe can then use the filter, also from dplyr, to filter observations (rows) before we group. For example, we could filter the years in the 18th Century (year&lt;1800 & year&gt;=1700) and calculate the average monthly temperatures then via;\n\nhistorical_temperature %&gt;%\n    filter(year&lt;1800 & year&gt;=1700) %&gt;%\n    group_by(month) %&gt;%\n    summarise(\"18th Century\"=mean(temperature, na.rm=TRUE))\n\n# A tibble: 12 × 2\n   month `18th Century`\n   &lt;fct&gt;          &lt;dbl&gt;\n 1 JAN             2.89\n 2 FEB             3.80\n 3 MAR             5.04\n 4 APR             7.88\n 5 MAY            11.3 \n 6 JUN            14.5 \n 7 JUL            16.0 \n 8 AUG            15.8 \n 9 SEP            13.5 \n10 OCT             9.40\n11 NOV             5.84\n12 DEC             3.89\n\n\nWe could then repeat this for the 21st Century…\n\nhistorical_temperature %&gt;%\n    filter(year&gt;=2000) %&gt;%\n    group_by(month) %&gt;%\n    summarise(\"21st Century\"=mean(temperature, na.rm=TRUE))\n\n# A tibble: 12 × 2\n   month `21st Century`\n   &lt;fct&gt;          &lt;dbl&gt;\n 1 JAN             4.73\n 2 FEB             4.93\n 3 MAR             6.60\n 4 APR             9.08\n 5 MAY            12.0 \n 6 JUN            14.9 \n 7 JUL            16.8 \n 8 AUG            16.4 \n 9 SEP            14.3 \n10 OCT            11.2 \n11 NOV             7.44\n12 DEC             5.12\n\n\n\n\n\n\n\n\nExercise\n\n\n\nUse filter, group_by and summarise to create tibbles that contain the average monthly temperatures for the 17th and 21st Centuries. Take the difference of these to calculate the change in average temperature for each month.\nNext calculate the minimum and maximum monthly temperatures for the 17th and 21st Centuries. Again, calculate the change in minimum and maximum temperatures for each month.\nFinally, what is the average increase in maximum monthly temperatures between the 16th and 21st Centuries?\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\nlibrary(tidyverse)\n\nLoad the data…\n\ntemperature &lt;- read_table(\n    \"https://raw.githubusercontent.com/Bristol-Training/intro-data-analysis-r/refs/heads/main/data/cetml1659on.txt\",\n    skip=6,\n    na=c(\"-99.99\", \"-99.9\"),\n    col_types=cols(\"DATE\"=col_integer())\n)\n\nCreate the month levels\n\nmonth_levels &lt;- c(\"JAN\", \"FEB\", \"MAR\", \"APR\", \"MAY\", \"JUN\",\n                  \"JUL\", \"AUG\", \"SEP\", \"OCT\", \"NOV\", \"DEC\")\n\nTidy the data…\n\nhistorical_temperature &lt;- temperature %&gt;%\n    select(-YEAR) %&gt;%\n    pivot_longer(c(\"JAN\", \"FEB\", \"MAR\", \"APR\", \"MAY\", \"JUN\",\n                   \"JUL\", \"AUG\", \"SEP\", \"OCT\", \"NOV\", \"DEC\"),\n                 names_to=\"month\",\n                 values_to=\"temperature\") %&gt;%\n    rename(year=DATE) %&gt;%\n    mutate(month=factor(month, month_levels))\n\nCalculate the mean monthly temperatures in the 17th Century\n\nc17th &lt;- historical_temperature %&gt;%\n     filter(year&lt;1700 & year&gt;=1600) %&gt;%\n     group_by(month) %&gt;%\n     summarise(\"temperature\"=mean(temperature, na.rm=TRUE), .groups=\"drop\")\n\n(the .groups=\"drop\" removes a warning message in newer versions of R. It is experimental, e.g. see this stackoverflow post)\nCalculate the mean monthly temperatures in the 21st Century\n\nc21st &lt;- historical_temperature %&gt;%\n     filter(year&gt;=2000) %&gt;%\n     group_by(month) %&gt;%\n     summarise(\"temperature\"=mean(temperature, na.rm=TRUE), .groups=\"drop\")\n\nNow add the difference to the c21st table and print it out\n\nc21st[\"change\"] &lt;- c21st[\"temperature\"] - c17th[\"temperature\"]\nc21st\n\n# A tibble: 12 × 3\n   month temperature change\n   &lt;fct&gt;       &lt;dbl&gt;  &lt;dbl&gt;\n 1 JAN          4.73  2.16 \n 2 FEB          4.93  2.00 \n 3 MAR          6.60  1.96 \n 4 APR          9.08  1.80 \n 5 MAY         12.0   1.33 \n 6 JUN         14.9   0.818\n 7 JUL         16.8   1.12 \n 8 AUG         16.4   1.26 \n 9 SEP         14.3   1.71 \n10 OCT         11.2   1.91 \n11 NOV          7.44  1.91 \n12 DEC          5.12  1.76 \n\n\nFrom this we can see that most of the warming is focused on the winter months.\nWe will now repeat this for the maximum and minimum temperatures…\n\nc17th_max &lt;- historical_temperature %&gt;%\n     filter(year&lt;1700 & year&gt;=1600) %&gt;%\n     group_by(month) %&gt;%\n     summarise(\"temperature\"=max(temperature, na.rm=TRUE), .groups=\"drop\")\nc21st_max &lt;- historical_temperature %&gt;%\n     filter(year&gt;=2000) %&gt;%\n     group_by(month) %&gt;%\n     summarise(\"temperature\"=max(temperature, na.rm=TRUE), .groups=\"drop\")\nc21st_max[\"change\"] &lt;- c21st_max[\"temperature\"] - c17th_max[\"temperature\"]\n\nc21st_max\n\n# A tibble: 12 × 3\n   month temperature change\n   &lt;fct&gt;       &lt;dbl&gt;  &lt;dbl&gt;\n 1 JAN           7    0.5  \n 2 FEB           7    1    \n 3 MAR           8.7  1.7  \n 4 APR          11.8  2.3  \n 5 MAY          13.4  0.400\n 6 JUN          16.1 -1.90 \n 7 JUL          19.7  1.7  \n 8 AUG          18.3  1.3  \n 9 SEP          16.8  1.8  \n10 OCT          13.3  1.8  \n11 NOV           9.6  1.6  \n12 DEC           9.7  3.2  \n\n\n\nc17th_min &lt;- historical_temperature %&gt;%\n     filter(year&lt;1700 & year&gt;=1600) %&gt;%\n     group_by(month) %&gt;%\n     summarise(\"temperature\"=min(temperature, na.rm=TRUE), .groups=\"drop\")\nc21st_min &lt;- historical_temperature %&gt;%\n     filter(year&gt;=2000) %&gt;%\n     group_by(month) %&gt;%\n     summarise(\"temperature\"=min(temperature, na.rm=TRUE), .groups=\"drop\")\nc21st_min[\"change\"] &lt;- c21st_min[\"temperature\"] - c17th_min[\"temperature\"]\n\nc21st_min\n\n# A tibble: 12 × 3\n   month temperature change\n   &lt;fct&gt;       &lt;dbl&gt;  &lt;dbl&gt;\n 1 JAN           1.4    4.4\n 2 FEB           2.8    3.8\n 3 MAR           2.7    1.7\n 4 APR           7.2    1.7\n 5 MAY          10.4    1.9\n 6 JUN          13.5    2  \n 7 JUL          15.2    1.7\n 8 AUG          14.9    1.9\n 9 SEP          12.6    2.1\n10 OCT           9.2    2.7\n11 NOV           5.2    2.2\n12 DEC          -0.7   -0.2\n\n\nFinally, we can get the average increase in monthly temperatures by calculating the mean of the change column in c21st\n\nmean(c21st[[\"change\"]])\n\n[1] 1.643698\n\n\n\n\n\nBecause we were working with tidy data the filtering and grouping of observations, and then generation of summary statistics was straightforward. This grammar (data is filtered, then grouped, then summarised) worked because the data was tidy. As we will see in the next section, a similar grammar for visualisation makes graph drawing equally logical.",
    "crumbs": [
      "Data analysis"
    ]
  },
  {
    "objectID": "pages/980-summary.html",
    "href": "pages/980-summary.html",
    "title": "Summary",
    "section": "",
    "text": "That’s all we have for this workshop. By now you should have a better understanding of how you can make your code more easily shared, reusable and tidy. In this workshow we have covered:\n\nSearch for and install R packages\nUsing R packages and their functions\nWriting your own functions\nError handling in functions\nWrite tidy code to work with tidy data with tidyverse\n\nThis has been only a brief introduction. You can learn more from these excellent free online resources:\n\nR for Data Science (2e) by Hadley Wickham, Mine Çetinkaya-Rundel and Garrett Grolemund. - this is a must-read book that really shows you how to do data science with R.\nggplot2: Elegant Graphics for Data Analysis, by Hadley Wickham, Danielle Navarro, and Thomas Lin Pedersen - this is an excellent book that show how to use ggplot for drawing graphs.\nAdvanced R, by Hadley Wickham - this book goes deeper into the R programming language.\nText mining with R: A Tidy approach, by Julia Silge and David Robinson - this book shows how to use tidy principles to perform text mining and sentiment analysis.\nStatistical Inference via Data Science: A ModernDive into R and the Tidyverse, by Chester Ismay and Albert Y. Kim - this book teaches statistical techniques, using R and the Tidyverse.\nThe R Graph Gallery - a large showcase of different ggplot graphs covering pretty every type of data visualisation you would want to perform. Examples with code! Find an example that matches the type of graph that you want to draw and then adapt that to your own data.\nMastering Shiny, by Hadley Wickham - This book teaches you how to use Shiny to turn your Tidyverse R data analysis and visualisations into interactive web pages and dashboards that you can share with your collaborators.",
    "crumbs": [
      "Summary"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction",
    "section": "",
    "text": "Welcome to this course on data analysis using R! This course is aimed at the intermediate R developer who wants to learn how to do useful data analysis tasks in R. It will focus on “modern R”, specifically using the tidyverse collection of packages which are designed for data science.\nFor the purpose of this course we will be using RStudio which provides you with a text editor and R console. Setting up instructions can be found here.\n\nIntended learning outcomes\nBy the end of this course, you will:\n\nFeel confident installing and using packages\nKnow how to write functions\nBe familiar with tydiverse ecosystem\nKnow how to read, filter and transform data\n\n\n\nHow to read this documentation\nIn this documentation, any time that we are seeing a small snippet of R code, we’ll see it written in a grey box like the following:\ncat(\"Hello, R\")\nIf the commands are executed by the machine we will see the output of them below enclosed on a vertical purple line:\n\ncat(\"Hello, R!\")\n\nHello, R!\n\n\nBy contrast, you will see larger pices of code as scripts with a given name, e.g. script.R, in a code block with darker header:\n\n\nscript.R\n\nname &lt;- \"Jean Golding\"\ncat(\"Hello,\", name, \"!\")\n\nWe may ask you to run a script using the Command Prompt (Windows) or Terminal (Mac and Linux). We will show you what commands to run and will look like this:\n\n\nTerminal/Command Prompt\n\nRscript script.R\n\nIn some cases we will introduce general programming concepts and structures using pseudocode, a high-level, easy-to-read syntax close to natural language. This should not be confused with R code and cannot be executed on your machine, but it is useful to describe how your code should behave. Here there is an example:\nFOR EACH sample IN my_study\n    IF (sample.value &gt; 100)\n        DO SOMETHING\n    OTHERWISE\n        DO SOMETHING ELSE\nThere are some exercices along this course, and it is important you try to answer them yourself to understand how R works. Exercises are shown in blue boxes followed by a yellow box that contains the answer of each exercise. We recommend you to try to answer each exercise yourself before looking at the solution.\n\n\n\n\n\n\nExercise\n\n\n\nThis is an exercise. You will need to click in the below box to see the answer.\n\n\n\n\n\n\n\n\nAnswer (click to open)\n\n\n\n\n\nThis is the answer.\n\n\n\nLast, we will highlight important points using green boxes like this one:\n\n\n\n\n\n\nKey points\n\n\n\nThese are important concepts and technical notes.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "pages/020-tibbles.html",
    "href": "pages/020-tibbles.html",
    "title": "Tibbles and filters",
    "section": "",
    "text": "As you may remember from the Intermediate R workshop, R is great at representing and manipulating tabular data. In “traditional” R, this was handled in data.frame, while in modern “tidyverse” R this is handled via a tibble.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nA tibble is a two (or possibly more) dimensional table of data.\n\ncensus &lt;- tibble(\"City\"=c(\"Paris\", \"Paris\", \"Paris\", \"Paris\",\n                          \"London\", \"London\", \"London\", \"London\",\n                          \"Rome\", \"Rome\", \"Rome\", \"Rome\"),\n                 \"year\"=c(2001, 2008, 2009, 2010,\n                          2001, 2006, 2011, 2015,\n                          2001, 2006, 2009, 2012),\n                 \"pop\"=c(2.148, 2.211, 2.234, 2.244,\n                         7.322, 7.657, 8.174, 8.615,\n                         2.547, 2.627, 2.734, 2.627))\n\nThis has created a tibble that we have assigned to the variable census. The column names are the keys (City, year and pop), while the data for each column is given in the values (the lists).\nYou can print a summary of the tibble via:\n\ncensus\n\n# A tibble: 12 × 3\n   City    year   pop\n   &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 Paris   2001  2.15\n 2 Paris   2008  2.21\n 3 Paris   2009  2.23\n 4 Paris   2010  2.24\n 5 London  2001  7.32\n 6 London  2006  7.66\n 7 London  2011  8.17\n 8 London  2015  8.62\n 9 Rome    2001  2.55\n10 Rome    2006  2.63\n11 Rome    2009  2.73\n12 Rome    2012  2.63\n\n\nNote that R will default to interpreting numbers as floating point (dbl). While this is correct for the pop (population) column, this is the wrong choice for the year. A better choice would be an integer. To force this, use as.integer to set the data type for the year column;\n\ncensus &lt;- tibble(\"City\"=c(\"Paris\", \"Paris\", \"Paris\", \"Paris\",\n                          \"London\", \"London\", \"London\", \"London\",\n                          \"Rome\", \"Rome\", \"Rome\", \"Rome\"),\n                 \"year\"=as.integer(c(2001, 2008, 2009, 2010,\n                                     2001, 2006, 2011, 2015,\n                                     2001, 2006, 2009, 2012)),\n                 \"pop\"=c(2.148, 2.211, 2.234, 2.244,\n                         7.322, 7.657, 8.174, 8.615,\n                         2.547, 2.627, 2.734, 2.627))\n\ncensus\n\n# A tibble: 12 × 3\n   City    year   pop\n   &lt;chr&gt;  &lt;int&gt; &lt;dbl&gt;\n 1 Paris   2001  2.15\n 2 Paris   2008  2.21\n 3 Paris   2009  2.23\n 4 Paris   2010  2.24\n 5 London  2001  7.32\n 6 London  2006  7.66\n 7 London  2011  8.17\n 8 London  2015  8.62\n 9 Rome    2001  2.55\n10 Rome    2006  2.63\n11 Rome    2009  2.73\n12 Rome    2012  2.63\n\n\nwill print\nYou access the contents of a tibble mostly by column, e.g.\n\ncensus[\"City\"]\n\n# A tibble: 12 × 1\n   City  \n   &lt;chr&gt; \n 1 Paris \n 2 Paris \n 3 Paris \n 4 Paris \n 5 London\n 6 London\n 7 London\n 8 London\n 9 Rome  \n10 Rome  \n11 Rome  \n12 Rome  \n\n\nwill return a tibble of just a single column containing the City data.\nYou can also access the columns by their index, e.g.\n\ncensus[1]\n\n# A tibble: 12 × 1\n   City  \n   &lt;chr&gt; \n 1 Paris \n 2 Paris \n 3 Paris \n 4 Paris \n 5 London\n 6 London\n 7 London\n 8 London\n 9 Rome  \n10 Rome  \n11 Rome  \n12 Rome  \n\n\nwill return the first column, so is identical to census[\"City\"].\nYou can also extract multiple columns by specifying them via c( ), e.g.\n\ncensus[c(\"City\", \"year\")]\n\n# A tibble: 12 × 2\n   City    year\n   &lt;chr&gt;  &lt;int&gt;\n 1 Paris   2001\n 2 Paris   2008\n 3 Paris   2009\n 4 Paris   2010\n 5 London  2001\n 6 London  2006\n 7 London  2011\n 8 London  2015\n 9 Rome    2001\n10 Rome    2006\n11 Rome    2009\n12 Rome    2012\n\n\nwill return a tibble with the City and year columns.\nTo access data by rows, you need to pass in the row index followed by a comma, e.g.\n\ncensus[1, ]\n\n# A tibble: 1 × 3\n  City   year   pop\n  &lt;chr&gt; &lt;int&gt; &lt;dbl&gt;\n1 Paris  2001  2.15\n\n\nwill return a tibble containing just the first row of data.\nYou can use ranges to get several rows, e.g.\n\ncensus[1:5, ]\n\n# A tibble: 5 × 3\n  City    year   pop\n  &lt;chr&gt;  &lt;int&gt; &lt;dbl&gt;\n1 Paris   2001  2.15\n2 Paris   2008  2.21\n3 Paris   2009  2.23\n4 Paris   2010  2.24\n5 London  2001  7.32\n\n\nwould return the first five rows, while\n\ncensus[seq(2, 10, 2), ]\n\n# A tibble: 5 × 3\n  City    year   pop\n  &lt;chr&gt;  &lt;int&gt; &lt;dbl&gt;\n1 Paris   2008  2.21\n2 Paris   2010  2.24\n3 London  2006  7.66\n4 London  2015  8.62\n5 Rome    2006  2.63\n\n\nwould return the even rows from 2 to 10.\nYou can access specific rows and columns via [row, column], e.g.\n\ncensus[1, 1]\n\n# A tibble: 1 × 1\n  City \n  &lt;chr&gt;\n1 Paris\n\n\nreturns a tibble containing just the first row and first column, while\n\ncensus[seq(2, 10, 2), \"year\"]\n\n# A tibble: 5 × 1\n   year\n  &lt;int&gt;\n1  2008\n2  2010\n3  2006\n4  2015\n5  2006\n\n\nwould return the year column of the even rows from 2 to 10, and\n\ncensus[5, 2:3]\n\n# A tibble: 1 × 2\n   year   pop\n  &lt;int&gt; &lt;dbl&gt;\n1  2001  7.32\n\n\nwould return the second and third columns of the fifth row.\nThe above functions all return a tibble that is a subset of the whole tibble. You can extract the data for a single column as a list via [[ ]] or $, e.g.\n\ncensus[[1]]\n\n [1] \"Paris\"  \"Paris\"  \"Paris\"  \"Paris\"  \"London\" \"London\" \"London\" \"London\"\n [9] \"Rome\"   \"Rome\"   \"Rome\"   \"Rome\"  \n\ncensus[[\"City\"]]\n\n [1] \"Paris\"  \"Paris\"  \"Paris\"  \"Paris\"  \"London\" \"London\" \"London\" \"London\"\n [9] \"Rome\"   \"Rome\"   \"Rome\"   \"Rome\"  \n\ncensus$City\n\n [1] \"Paris\"  \"Paris\"  \"Paris\"  \"Paris\"  \"London\" \"London\" \"London\" \"London\"\n [9] \"Rome\"   \"Rome\"   \"Rome\"   \"Rome\"  \n\n\nand can then extract data from those lists via sub-indexing, e.g.\n\ncensus$City[1]\n\n[1] \"Paris\"\n\n\nwould return the City column data for the first row.\n\nQuerying\nWe can start to ask questions of our data using the filter function.\n\ncensus %&gt;% filter(City==\"Paris\")\n\n# A tibble: 4 × 3\n  City   year   pop\n  &lt;chr&gt; &lt;int&gt; &lt;dbl&gt;\n1 Paris  2001  2.15\n2 Paris  2008  2.21\n3 Paris  2009  2.23\n4 Paris  2010  2.24\n\n\n(note that we didn’t need to put double quotes around City in the filter - it knows that this is a column name. Also, look here if you need to refresh your knowledge of the %&gt;% operator).\nThis has returned a new tibble, which you can then access using the same methods as above, e.g.\n\n(census %&gt;% filter(City==\"Paris\"))[\"year\"]\n\n# A tibble: 4 × 1\n   year\n  &lt;int&gt;\n1  2001\n2  2008\n3  2009\n4  2010\n\n\nYou can also test if the rows of a tibble match a condition, e.g.\n\ncensus[\"City\"] == \"Paris\"\n\n       City\n [1,]  TRUE\n [2,]  TRUE\n [3,]  TRUE\n [4,]  TRUE\n [5,] FALSE\n [6,] FALSE\n [7,] FALSE\n [8,] FALSE\n [9,] FALSE\n[10,] FALSE\n[11,] FALSE\n[12,] FALSE\n\n\nreturns a set of TRUE / FALSE values for each row, depending on whether the City value of that row was equal to Paris.\n\n\nAdding new columns\nNew columns can be added to a tibble simply by assigning them by index (as you would for a dictionary);\n\ncensus[\"continental\"] &lt;- census[\"City\"] != \"London\"\ncensus\n\n# A tibble: 12 × 4\n   City    year   pop continental\n   &lt;chr&gt;  &lt;int&gt; &lt;dbl&gt; &lt;lgl&gt;      \n 1 Paris   2001  2.15 TRUE       \n 2 Paris   2008  2.21 TRUE       \n 3 Paris   2009  2.23 TRUE       \n 4 Paris   2010  2.24 TRUE       \n 5 London  2001  7.32 FALSE      \n 6 London  2006  7.66 FALSE      \n 7 London  2011  8.17 FALSE      \n 8 London  2015  8.62 FALSE      \n 9 Rome    2001  2.55 TRUE       \n10 Rome    2006  2.63 TRUE       \n11 Rome    2009  2.73 TRUE       \n12 Rome    2012  2.63 TRUE       \n\n\n\n\n\n\n\n\nExercise\n\n\n\nCreate the tibble containing the census data for the three cities.\nSelect the data for the year 2001. Which city had the smallest population that year?\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nImport the tidyverse and load up the data\n\nlibrary(tidyverse)\n\ncensus &lt;- tibble(\"City\"=c(\"Paris\", \"Paris\", \"Paris\", \"Paris\",\n                          \"London\", \"London\", \"London\", \"London\",\n                          \"Rome\", \"Rome\", \"Rome\", \"Rome\"),\n                 \"year\"=as.integer(c(2001, 2008, 2009, 2010,\n                                     2001, 2006, 2011, 2015,\n                                     2001, 2006, 2009, 2012)),\n                 \"pop\"=c(2.148, 2.211, 2.234, 2.244,\n                         7.322, 7.657, 8.174, 8.615,\n                         2.547, 2.627, 2.734, 2.627))\n\nWe start by grabbing the data for the year we care about\n\ncensus %&gt;% filter(year==2001)\n\n# A tibble: 3 × 3\n  City    year   pop\n  &lt;chr&gt;  &lt;int&gt; &lt;dbl&gt;\n1 Paris   2001  2.15\n2 London  2001  7.32\n3 Rome    2001  2.55\n\n\nWe can see that the smallest population was in Paris that year but let’s try to extract it using R.\n\npop &lt;- (census %&gt;% filter(year==2001))$pop\npop\n\n[1] 2.148 7.322 2.547\n\n\nThe min function returns the minimum of a list of numbers. If we run this on pop then we will get the smallest number.\n\nmin_pop &lt;- min(pop)\nmin_pop\n\n[1] 2.148\n\n\nWe can now use this minimum population to further filter the census data;\n\ncensus %&gt;% filter(year==2001) %&gt;% filter(pop==min_pop)\n\n# A tibble: 1 × 3\n  City   year   pop\n  &lt;chr&gt; &lt;int&gt; &lt;dbl&gt;\n1 Paris  2001  2.15\n\n\nFinally(!) we can extract the City column\n\n(census %&gt;% filter(year==2001) %&gt;% filter(pop==min_pop))[\"City\"]\n\n# A tibble: 1 × 1\n  City \n  &lt;chr&gt;\n1 Paris\n\n\nAll of this could be combined into a single (dense) expression, e.g.\n\ncity &lt;- (census %&gt;%\n           filter(year==2001) %&gt;%\n           filter(pop==min((census %&gt;% filter(year==2001))[\"pop\"]))\n         )[\"City\"]\ncity\n\n# A tibble: 1 × 1\n  City \n  &lt;chr&gt;\n1 Paris\n\n\n:::",
    "crumbs": [
      "Tibbles and filters"
    ]
  },
  {
    "objectID": "pages/990-contributors.html",
    "href": "pages/990-contributors.html",
    "title": "Contributors",
    "section": "",
    "text": "This course has been developed by the Jean Golding Insitute.\nThese materials were originally written by Christopher Woods https://chryswoods.com/intermediate_r/, based on Introduction to Data Analysis in Python by Matt Williams https://milliams.com/courses/data_analysis_python/.",
    "crumbs": [
      "Contributors"
    ]
  },
  {
    "objectID": "pages/010-workspace-setup.html",
    "href": "pages/010-workspace-setup.html",
    "title": "Workspace setup",
    "section": "",
    "text": "There are lots of different ways to run R code and many tools to help you write it. You don’t require any special tools to create an R script, a simple text editor like Notepad on Windows is sufficient. More advanced tools include IDEs like RStudio or Visual Studio Code.\nFor this workshop we will be keeping things as simple as possible in order to allow us to focus on the topics we’re learning without having to learn too many extra tools along the way.\nFor the purpose of this course we will be using a free tool called RStudio which provides you with an integrated enviroment where you can write and run R code. The easiest way to get access to R and RStudio is first downloading and installing the latest R version from https://cran.rstudio.com/, and after downloading and installing RStudio from https://posit.co/download/rstudio-desktop/. You may need administrator access to install R and RStudio on your computer. Both tools are freely available for Windows, MacOS and Linux.\n\n\n\n\n\n\nInstallation on University managed computers\n\n\n\nIf you are using a University of Bristol computer, you will find R and RStudio in Company Portal.\n\n\nOnce both are installed, you can open RStudio and will look something like this:\n\nThe way that we will be setting up the space is to have a text editor on the top-left side of the screen and the R console on the bottom-left side. We’ll use the editor to write our code and the console to run it. On the right side we can keep other tabs open.\n\nWorking directory\nSetting up a working directory helps organize your project files and ensures that your code can find any necessary resources and dependencies. We will revisit this concept later on, but for now be mindful that the space where you save your scripts has to be the same than the working directory where R console and/or your Command Prompt/Terminal are working,\nIn R Console you can print the current working directory it with\ngetwd()\n\n\n[1] \"/Users/ab12345\"\n\n\nAlternatively, if you are using the Command Prompt (Windows) you can check your current directory with\n\n\nCommand Prompt\n\ncd\n\nOr if you are using a Terminal (MacOS and Linux) you can check your current directory with\n\n\nTerminal\n\npwd\n\nWe’re now ready to get started!",
    "crumbs": [
      "Workspace setup"
    ]
  },
  {
    "objectID": "pages/030-files.html",
    "href": "pages/030-files.html",
    "title": "Reading from files",
    "section": "",
    "text": "One of the most common situations is that you have some data file containing the data you want to read. Perhaps this is data you’ve produced yourself or maybe it’s from a collegue. In an ideal world the file will be perfectly formatted and will be trivial to import into R but since this is so often not the case, R provides a number of features to make your life easier.\nA good documentation on reading and writing files is available in R for Data Science (2e) but first it’s worth noting the common formats that R can work with:\n\nComma-separated files (or tab-separated, space-separated etc)\nExcel spreadsheets\nHDF5 files\nSQL databases\n\nFor this course we will focus on plain-text CSV files as they are perhaps the most common format. Imagine we have a CSV (comma-separated values) file. The example we will use today is available at city_pop.csv. Open that file in your browser and you will see;\nThis is an example CSV file\nThe text at the top here is not part of the data but instead is here\nto describe the file. You'll see this quite often in real-world data.\nA -1 signifies a missing value.\n\nyear;London;Paris;Rome\n2001;7.322;2.148;2.547\n2006;7.652;;2.627\n2008;-1;2.211;\n2009;-1;2.234;2.734\n2011;8.174;;\n2012;-1;2.244;2.627\n2015;8.615;;\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nWe can use the tidyverse function read_csv to read the file and convert it to a tibble. The function read_csv is part of the readr package that is installed with the tidyverse.\nFull documentation for this function can be found in the manual or, as with any R function, directly in the notebook by putting a ? before the name:\n\n?read_csv\n\nThe first argument to the function is called file, the documentation for which begins:\nEither a path to a file, a connection, or literal data (either a single string or a raw vector).\n\nFiles ending in .gz, .bz2, .xz, or .zip will be automatically uncompressed. Files starting \nwith http://, https://, ftp://, or ftps:// will be automatically downloaded. \nRemote gz files can also be automatically downloaded and decompressed.\nThis means that we can take our URL and pass it directly (or via a variable) to the function:\n\ncity_pop_file &lt;- \"https://raw.githubusercontent.com/Bristol-Training/intro-data-analysis-r/refs/heads/main/data/city_pop.csv\"\nread_csv(city_pop_file)\n\nRows: 11 Columns: 1\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): This is an example CSV file\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 11 × 1\n   `This is an example CSV file`                                        \n   &lt;chr&gt;                                                                \n 1 The text at the top here is not part of the data but instead is here \n 2 to describe the file. You'll see this quite often in real-world data.\n 3 A -1 signifies a missing value.                                      \n 4 year;London;Paris;Rome                                               \n 5 2001;7.322;2.148;2.547                                               \n 6 2006;7.652;;2.627                                                    \n 7 2008;-1;2.211;                                                       \n 8 2009;-1;2.234;2.734                                                  \n 9 2011;8.174;;                                                         \n10 2012;-1;2.244;2.627                                                  \n11 2015;8.615;;                                                         \n\n\nWe can see that by default it’s done a fairly bad job of parsing the file (this is mostly because I’ve construsted the city_pop.csv file to be as obtuse as possible). It’s making a lot of assumptions about the structure of the file but in general it’s taking quite a naïve approach.\nThe first thing we notice is that it’s treating the text at the top of the file as though it’s data. Checking the documentation we see that the simplest way to solve this is to use the skip argument to the function to which we give an integer giving the number of rows to skip:\n\nread_csv(\n    city_pop_file,\n    skip=5\n)\n\nRows: 7 Columns: 1\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): year;London;Paris;Rome\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 7 × 1\n  `year;London;Paris;Rome`\n  &lt;chr&gt;                   \n1 2001;7.322;2.148;2.547  \n2 2006;7.652;;2.627       \n3 2008;-1;2.211;          \n4 2009;-1;2.234;2.734     \n5 2011;8.174;;            \n6 2012;-1;2.244;2.627     \n7 2015;8.615;;            \n\n\nThe next most obvious problem is that it is not separating the columns at all. This is because read_csv is a special case of the more general read_delim that sets the separator (also called the delimiter) delim to a comma ,.\nWe can set the separator to ; by changing to read_delim and setting delim equal to ;\n\nread_delim(\n    city_pop_file,\n    skip=5,\n    delim=\";\"\n)\n\nRows: 7 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\ndbl (4): year, London, Paris, Rome\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 7 × 4\n   year London Paris  Rome\n  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  2001   7.32  2.15  2.55\n2  2006   7.65 NA     2.63\n3  2008  -1     2.21 NA   \n4  2009  -1     2.23  2.73\n5  2011   8.17 NA    NA   \n6  2012  -1     2.24  2.63\n7  2015   8.62 NA    NA   \n\n\nNow it’s actually starting to look like a real table of data.\nReading the descriptive header of our data file we see that a value of -1 signifies a missing reading so we should mark those too. This can be done after the fact but it is simplest to do it at import-time using the na argument:\n\nread_delim(    \n    city_pop_file,\n    skip=5,\n    delim=\";\",\n    na=\"-1\"\n)\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\n\n\nRows: 7 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\ndbl (4): year, London, Paris, Rome\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 7 × 4\n   year London Paris  Rome\n  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  2001   7.32  2.15  2.55\n2  2006   7.65 NA     2.63\n3  2008  NA     2.21 NA   \n4  2009  NA     2.23  2.73\n5  2011   8.17 NA    NA   \n6  2012  NA     2.24  2.63\n7  2015   8.62 NA    NA   \n\n\nThe next issue is that you can see that the year has been read in as a floating point (double) number, rather than as an integer. Each column is read using a parser, that converts the text data in the file into data of the appropriate type. R will guess which parser to use, with this helpfully reported to the R console:\nRows: 7 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\ndbl (4): year, London, Paris, Rome\nIn this case, R has guessed that all of the columns contain floating point numbers, and so it has used the col_double() specification, which calls the parse_double() function to convert the text from those columns from the file into numbers.\nThe tidyverse supplies many parsers, e.g. parse_integer(), parse_date() etc. More detail about these parsers (including how to parse different date formats, different number formats etc.) can be found in the free online book R for Data Science (2e) by Hadley Wickham, Mine Çetinkaya-Rundel and Garrett Grolemund.\nYou can set the parser to use for a column by specifying the column types via the col_types argument. We want the year to be an integer, so we can write:\n\nread_delim(    \n    city_pop_file,\n    skip=5,\n    delim=\";\",\n    na=\"-1\",\n    col_types=cols(\"year\"=col_integer())\n)\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\n\n\n# A tibble: 7 × 4\n   year London Paris  Rome\n  &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  2001   7.32  2.15  2.55\n2  2006   7.65 NA     2.63\n3  2008  NA     2.21 NA   \n4  2009  NA     2.23  2.73\n5  2011   8.17 NA    NA   \n6  2012  NA     2.24  2.63\n7  2015   8.62 NA    NA   \n\n\nNote that col_guess(), which guesses the right type of data, is used for any columns that you don’t specify.\nyear    London  Paris   Rome\n&lt;int&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n2001    7.322   2.148   2.547\n2006    7.652   NA      2.627\n2008    NA      2.211   NA\n2009    NA      2.234   2.734\n2011    8.174   NA      NA\n2012    NA      2.244   2.627\n2015    8.615   NA      NA\nFinally, we want to assign this tibble to a variable, called census;\n\ncensus &lt;- read_delim(\n    city_pop_file,\n    skip=5,\n    delim=\";\",\n    na=\"-1\",\n    col_types=cols(\"year\"=col_integer())\n)\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\n\n\nThat covers the basics of reading in data with R. For more information please read the excellent free online book R for Data Science (2e) by Hadley Wickham, Mine Çetinkaya-Rundel and Garrett Grolemund, check out the documentation for readr, or check out the really handy official readr cheat sheet.\nNext, now that we have our dataset loaded, we will do something useful with our data and plot it.\n\n\n\n\n\n\nExercise\n\n\n\nRead the file cetml1659on.txt into a tibble (this data is originally from the Met Office and there’s a description of the format there too). This contains some historical weather data for a location in the UK. Import that file as a tibble using read_table, making sure that you cover all the possible NA values.\nHow many years had a negative average temperature in January?\nWhat was the average temperature in June over the years in the data set?\n\n\n\n\n\n\n\n\nAnswer (click to open)\n\n\n\n\n\nImport the tidyverse\n\nlibrary(tidyverse)\n\nRead in the file. As whitespace is the delimiter, we need to use read_table. Note that read_delim with delim=\" \" is the wrong choice as it will try to split on single whitespace characters. read_table is the right choice for multiple whitespace separators.\nNote that we should read the DATE as an integer, as it is a year.\n\ntemperature &lt;- read_table(\n    \"https://raw.githubusercontent.com/Bristol-Training/intro-data-analysis-r/refs/heads/main/data/cetml1659on.txt\",\n    skip=6,\n    na=c(\"-99.99\", \"-99.9\"),\n    col_types=cols(\"DATE\"=col_integer())\n)\ntemperature\n\n# A tibble: 362 × 14\n    DATE   JAN   FEB   MAR   APR   MAY   JUN   JUL   AUG   SEP   OCT   NOV   DEC\n   &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  1659     3     4     6     7    11    13    16    16    13    10     5     2\n 2  1660     0     4     6     9    11    14    15    16    13    10     6     5\n 3  1661     5     5     6     8    11    14    15    15    13    11     8     6\n 4  1662     5     6     6     8    11    15    15    15    13    11     6     3\n 5  1663     1     1     5     7    10    14    15    15    13    10     7     5\n 6  1664     4     5     5     8    11    15    16    16    13     9     6     4\n 7  1665     1     1     5     7    10    14    16    15    13     9     6     2\n 8  1666     4     5     6     8    11    15    18    17    14    11     6     3\n 9  1667     0     4     2     7    10    15    17    16    13     9     6     3\n10  1668     5     5     5     8    10    14    16    16    14    10     6     5\n# ℹ 352 more rows\n# ℹ 1 more variable: YEAR &lt;dbl&gt;\n\n\nHow many years had a negative average temperature in January?\n\nnegative_jan &lt;- temperature %&gt;% filter(temperature[\"JAN\"] &lt; 0)\n\nWarning: Using one column matrices in `filter()` was deprecated in dplyr 1.1.0.\nℹ Please use one dimensional logical vectors instead.\n\nnegative_jan\n\n# A tibble: 20 × 14\n    DATE   JAN   FEB   MAR   APR   MAY   JUN   JUL   AUG   SEP   OCT   NOV   DEC\n   &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  1684  -3    -1     3     6.5  13    15    16    15.5  12    11     3     4  \n 2  1695  -1     0.5   3.5   5.5   9    13    13.5  13    11.5   9     5.5   4  \n 3  1709  -1.5   2     3     9    12    14.5  15.5  15.5  13.5  10     7.5   3.5\n 4  1716  -2     3     4.5   9    10.5  14    15.5  15.5  12.5   9.5   5.5   3  \n 5  1740  -2.8  -1.6   3.9   6.4   8.6  12.8  15.3  14.7  14     5.3   3.3   2.2\n 6  1763  -0.8   4.9   5.4   8.9  10.2  14.6  15.3  15.3  13.1   8.3   5.8   6.2\n 7  1776  -1.6   3.8   6.4   9.4  10.8  14.1  16.3  15.2  12.9  10.2   6.2   4.4\n 8  1780  -0.9   2.1   7.9   6.3  12.8  14.2  16.8  17.6  15.6   9.1   4.4   3.2\n 9  1784  -0.6   1.4   2.7   5.7  13.5  13.7  15.2  14    14.8   7.8   5.5   0.3\n10  1795  -3.1   0.8   3.9   7.7  10.9  13.2  15.2  16.6  16    11.7   4.5   6.6\n11  1814  -2.9   1.4   2.9   9.6   9.2  12.2  16    14.7  12.8   8.1   4.7   4.3\n12  1820  -0.3   3.2   4.7   8.9  11.4  13.6  15.7  14.7  12.3   8.1   5.6   4.7\n13  1823  -0.1   3.1   5     6.7  12.2  12.3  14.1  14.4  12.5   8.4   7.1   4.8\n14  1830  -0.2   2.2   7.7   8.9  12    12.7  16.2  13.7  11.9  10.4   6.9   1.8\n15  1838  -1.5   0.4   4.9   6.1  10.5  14.4  15.6  15.1  12.7   9.8   4.6   4  \n16  1879  -0.7   3.1   4.7   5.7   8.9  12.9  13.6  14.5  12.6   8.9   4.1   0.7\n17  1881  -1.5   3.2   5.3   7.3  11.8  13.7  16.2  13.9  12.7   7.3   8.9   3.9\n18  1940  -1.4   2.6   6     8.7  12.5  16.4  15.1  15.6  12.8   9.6   6.9   3.8\n19  1963  -2.1  -0.7   6     8.7  10.6  14.9  15.2  14.3  12.9  11.1   8.2   2.6\n20  1979  -0.4   1.2   4.7   7.8  10    13.9  16.2  14.9  13.5  11.3   6.8   5.8\n# ℹ 1 more variable: YEAR &lt;dbl&gt;\n\n\n\nnum_negative_jan &lt;- as.numeric(count(negative_jan))\nnum_negative_jan\n\n[1] 20\n\n\nWhat was the average temperature in June over the years in the data set?\n\njun_average &lt;- mean(temperature[[\"JUN\"]])\njun_average\n\n[1] 14.33757\n\n\n(note that we have to get the column data, and not a 1-column tibble, hence why we use [[ ]])",
    "crumbs": [
      "Reading from files"
    ]
  }
]